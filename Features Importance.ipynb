{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features Importance Implementation##\n",
    "\n",
    "In this analysis, the stability selection which is a wrapper method is used to rank the features in terms of their power to predict the labels. In this method, the features ranking is implemented over several iterations and in each iteration a subset of randomly selected samples (observations) and features are used. In each iteration, we use a regularized Logistic Regression algorithm to train a classifier and then the features are ranked based on their weights (the higher the weight, the higher the rank is).\n",
    "\n",
    "After completing all the iterations, the features are ranked based on the percentage of times that they are selected as the most important feature. This way, the features that are more frequently selected as the most important feature through iterations have scores close to 100% and the least important features have scores close to 0%. By randomly selecting features in each iteration, in some iterations, the strongest features will be absent and other strong features will have the chance to be selected as the strongest feature, so in the end all the features will be ranked properly according to the percentage of times they appear as the strongest feature.\n",
    "\n",
    "The first advantage of this method is that the features rankings drop smoothly, and hence this ranking can be used for interpretation. Another advantage is that the result of this method is stable meaning that if we run this algorithm again, the result of the new implementation would be close to the results of the previous implementations, which also gives us the power to interpret the features importance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stability Selection via Sckit-Learn\n",
    "\n",
    "Here, the stability selection algortihm is implemented using RandomizedLogisticRegression class available in Scikit-Learn package, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedLogisticRegression(C=1, fit_intercept=True,\n",
       "               memory=Memory(cachedir=None), n_jobs=1, n_resampling=200,\n",
       "               normalize=True, pre_dispatch='3*n_jobs', random_state=20,\n",
       "               sample_fraction=0.5, scaling=0.5, selection_threshold=0.25,\n",
       "               tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import RandomizedLogisticRegression\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "# to avoid deprecation warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "# to read the csv data using pandas\n",
    "task_data = pd.read_csv('task_data.csv')\n",
    "\n",
    "# to prepare the X and Y(labels)\n",
    "colNames = task_data.columns[task_data.columns.str.contains('sensor')]\n",
    "X = task_data.loc[:, colNames]\n",
    "Y = task_data.class_label\n",
    "\n",
    "# to implement randomized logistic regression. Here, the sample_fraction \n",
    "# flag is set to 0.5, which defines the fraction of samples that is randomly \n",
    "# selected and used in each iteration of this algorithm.\n",
    "randLog = RandomizedLogisticRegression(sample_fraction=0.5, random_state=20)\n",
    "randLog.fit(X, Y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranked Features ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features sorted by their score:\n",
      "The score of sensor8 is 0.99.\n",
      "The score of sensor4 is 0.85.\n",
      "The score of sensor0 is 0.62.\n",
      "The score of sensor3 is 0.49.\n",
      "The score of sensor1 is 0.05.\n",
      "The score of sensor7 is 0.02.\n",
      "The score of sensor5 is 0.01.\n",
      "The score of sensor9 is 0.00.\n",
      "The score of sensor6 is 0.00.\n",
      "The score of sensor2 is 0.00.\n"
     ]
    }
   ],
   "source": [
    "# to print the result\n",
    "print(\"Features sorted by their score:\")\n",
    "sortedFeatures = sorted(zip(randLog.scores_, colNames), reverse=True)\n",
    "for i in range(len(sortedFeatures)):\n",
    "    print('The score of {} is {:.2f}.'.format(sortedFeatures[i][1], \n",
    "                                              sortedFeatures[i][0]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
